{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Generation Script\n",
    "## CS 72 Final Project\n",
    "### John Guerrerio\n",
    "### john.j.guerrerio.26@dartmouth.edu\n",
    "\n",
    "Last updated March 10, 2024\\\n",
    "\\\n",
    "This notebook contains the code to generate the dataset for the Inbox Guardian classification task.  It uses the Gmail API to scrape all emails in a user's inbox with the labels \"Unimportant,\" \"Normal,\" and \"Urgent,\" cleans and preprocesses them, and writes them to a csv.  Note this script requires you to log in to your google account to run (this generates a crednetials.json file and a token.json; I have not included my versions of these files to protect the privacy of my account)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import base64\n",
    "import re\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell handles logging into your google account\n",
    "SCOPES = ['https://www.googleapis.com/auth/gmail.readonly','https://www.googleapis.com/auth/gmail.modify']\n",
    "\n",
    "creds = None\n",
    "# The file token.json stores the user's access and refresh tokens, and is\n",
    "# created automatically when the authorization flow completes for the first\n",
    "# time.\n",
    "if os.path.exists('../token.json'):\n",
    "    creds = Credentials.from_authorized_user_file('../token.json', SCOPES)\n",
    "# If there are no (valid) credentials available, let the user log in.\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(               \n",
    "        # your creds file here. Please create json file as here https://cloud.google.com/docs/authentication/getting-started\n",
    "            '../credentials.json', SCOPES)\n",
    "        creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for the next run\n",
    "        with open('../token.json', 'w') as token:\n",
    "            token.write(creds.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "CHAT: CHAT\n",
      "SENT: SENT\n",
      "INBOX: INBOX\n",
      "IMPORTANT: IMPORTANT\n",
      "TRASH: TRASH\n",
      "DRAFT: DRAFT\n",
      "SPAM: SPAM\n",
      "CATEGORY_FORUMS: CATEGORY_FORUMS\n",
      "CATEGORY_UPDATES: CATEGORY_UPDATES\n",
      "CATEGORY_PERSONAL: CATEGORY_PERSONAL\n",
      "CATEGORY_PROMOTIONS: CATEGORY_PROMOTIONS\n",
      "CATEGORY_SOCIAL: CATEGORY_SOCIAL\n",
      "STARRED: STARRED\n",
      "UNREAD: UNREAD\n",
      "Normal: Label_3234030140869167843\n",
      "Urgent: Label_502346772578880845\n",
      "Unimportant: Label_6179828275384677292\n"
     ]
    }
   ],
   "source": [
    "service = build(\"gmail\", \"v1\", credentials=creds)\n",
    "# get all labels assosiated with a user's gmail\n",
    "results = service.users().labels().list(userId=\"me\").execute()\n",
    "labels = results.get(\"labels\", [])\n",
    "\n",
    "if not labels:\n",
    "  print(\"No labels found.\")\n",
    "else:\n",
    "  print(\"Labels:\")\n",
    "  for label in labels:\n",
    "    # print all labels assosiated with a user's gmail - sanity check to ensure we have the urgent, normal and unimportant labels\n",
    "    # also allows us to get internal label ids, which are necessary to scrape the messages assosiated with these labels\n",
    "    print(str(label[\"name\"]) + \": \" + str(label[\"id\"])) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_message(msg):\n",
    "    \"\"\"\n",
    "    This function handles converting a message retrieved via the Gmail API to a human readable format.  We have to read the message body\n",
    "    (which is located in a different part of the information Google API returns depending on the number/type of attachments) and decode the\n",
    "    base64 body to plain text\n",
    "\n",
    "    Args:\n",
    "        msg: The message returned by the Gmail API to decode\n",
    "    Returns:\n",
    "        text: A plaintext version of the message body\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # handles fetching the body of emails with different types/numbers of attachments\n",
    "    if 'parts' in msg['payload']:\n",
    "        if msg['payload']['parts'][0]['mimeType'] == 'multipart/alternative':\n",
    "            message_raw = msg['payload']['parts'][0]['parts'][0]['body']['data']    \n",
    "        else:\n",
    "            if \"data\" in msg['payload']['parts'][0][\"body\"]:\n",
    "                message_raw = msg['payload']['parts'][0]['body']['data']\n",
    "            else:\n",
    "                if msg['payload']['parts'][0][\"parts\"][0][\"mimeType\"] == 'multipart/alternative':\n",
    "                    message_raw = msg['payload']['parts'][0][\"parts\"][0][\"parts\"][0]['body']['data']\n",
    "                else:\n",
    "                    message_raw = msg['payload']['parts'][0][\"parts\"][0][\"body\"][\"data\"]\n",
    "                    \n",
    "    else:\n",
    "        message_raw = msg['payload']['body']['data']\n",
    "\n",
    "    # decode message body to plain text\n",
    "    try:\n",
    "        byte_code = base64.urlsafe_b64decode(message_raw)\n",
    "        text = byte_code.decode(\"utf-8\")\n",
    "        return text\n",
    "    except BaseException as error:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_metadata(msg):\n",
    "    \"\"\"\n",
    "    Parses out metadata from a message returned by Gmail API\n",
    "    \n",
    "    Args:\n",
    "        msg: The message returned by the Gmail API to decode\n",
    "    Returns:\n",
    "        ret: A list containing the sender and subject of a message\n",
    "    \"\"\"\n",
    "\n",
    "    ret = [\" \", \" \"]\n",
    "    \n",
    "    # loop over all message metadata\n",
    "    for values in msg['payload']['headers']: \n",
    "        name = values['name']\n",
    "        if name == 'From':\n",
    "            ret[0] = values[\"value\"]\n",
    "        if name == \"Subject\":\n",
    "            ret[1] = values[\"value\"]\n",
    "    return ret\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_messages(messages, label):\n",
    "    \"\"\"\n",
    "    Reads over all messages belonging to a specific Gmail Label, and converts them to csv formatted lines\n",
    "\n",
    "    Args:\n",
    "        messages: The messages belonging to a specific Gmail label to read over\n",
    "        label: The label to assign each message (we only read messages belonging to a single label in this function, so all messages should get the same label)\n",
    "    Returns:\n",
    "        text: A csv formatted string containing information about all messages in messages\n",
    "    \"\"\"\n",
    "\n",
    "    text = \"\"\n",
    "\n",
    "    for message in messages:\n",
    "        # fetch more specific information about each message\n",
    "        msg = service.users().messages().get(userId='me', id=message['id']).execute()\n",
    "        \n",
    "        # get sender/subject and parse out special characters\n",
    "        metadata = parse_metadata(msg)\n",
    "        sender = re.sub('[\\n\\r\\t,]+', ' ', metadata[0])\n",
    "        subject = re.sub('[\\n\\r\\t,]+', ' ', metadata[1])\n",
    "\n",
    "        # filter out special characters via regular expressions, html code via Beautiful soup\n",
    "        body = BeautifulSoup(re.sub('[\\n\\r\\t,]+', ' ', decode_message(msg))).get_text()\n",
    "\n",
    "        meta = f'{sender} {subject}' # sender and subject concatendated \n",
    "        full = f'{meta} {body}' # sender, subject, and body concatenated \n",
    "        \n",
    "        line = f'{sender},{subject},{body},{meta},{full},{label}\\n' \n",
    "        \n",
    "        text += line\n",
    "\n",
    "    print(f'Processed {len(messages)} documents')\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve all messages assosiated with each label\n",
    "spam = service.users().messages().list(userId='me', labelIds=['Label_6179828275384677292'], maxResults=500).execute() \n",
    "urgent = service.users().messages().list(userId='me', labelIds=['Label_502346772578880845'], maxResults=500).execute()\n",
    "normal = service.users().messages().list(userId='me', labelIds=['Label_3234030140869167843'], maxResults=500).execute()\n",
    "\n",
    "spamMessages = spam.get('messages',[]);\n",
    "urgentMessages = urgent.get('messages',[]);\n",
    "normalMessages = normal.get('messages',[]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7z/wmn1d5sn5qv9t2zl5pzldffm0000gn/T/ipykernel_89180/3866392165.py:24: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  body = BeautifulSoup(re.sub('[\\n\\r\\t,]+', ' ', decode_message(msg))).get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 262 documents\n",
      "Processed 184 documents\n",
      "Processed 90 documents\n"
     ]
    }
   ],
   "source": [
    "# write messages to a csv\n",
    "# note this csv is NOT shuffled - we will do this during model training\n",
    "# extra emails come from email chains, where each individual email counts as its own message\n",
    "\n",
    "if os.path.isfile(\"fullDataset.csv\"):\n",
    "    os.remove(\"fullDataset.csv\")\n",
    "    \n",
    "with open(\"fullDataset.csv\", \"a\") as f:\n",
    "    f.write(\"Sender,Subject,Body,Meta,Full,Label\\n\")\n",
    "    f.write(read_messages(spamMessages, 0))\n",
    "    f.write(read_messages(normalMessages, 1))\n",
    "    f.write(read_messages(urgentMessages, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sender</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>Meta</th>\n",
       "      <th>Full</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Womens Network Dartmouth &lt;Womens.Network.Dartm...</td>\n",
       "      <td>YOU'RE INVITED: SPA NIGHT TOMORROW 8PM</td>\n",
       "      <td>As the term concludes  take a study break and ...</td>\n",
       "      <td>Womens Network Dartmouth &lt;Womens.Network.Dartm...</td>\n",
       "      <td>Womens Network Dartmouth &lt;Womens.Network.Dartm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dartmouth Bikes &lt;Dartmouth.Bikes@dartmouth.edu&gt;</td>\n",
       "      <td>Open Bike Shop Hours (Free Lube!) Tuesday Morn...</td>\n",
       "      <td>Open shop hours are available for the communit...</td>\n",
       "      <td>Dartmouth Bikes &lt;Dartmouth.Bikes@dartmouth.edu...</td>\n",
       "      <td>Dartmouth Bikes &lt;Dartmouth.Bikes@dartmouth.edu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Collis Governing Board &lt;Collis.Governing.Board...</td>\n",
       "      <td>microbrews &lt;3</td>\n",
       "      <td>CGB Microbrews where: One Wheelock (Collis) wh...</td>\n",
       "      <td>Collis Governing Board &lt;Collis.Governing.Board...</td>\n",
       "      <td>Collis Governing Board &lt;Collis.Governing.Board...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The New York Times &lt;nytdirect@nytimes.com&gt;</td>\n",
       "      <td>Breaking news: $1 billion donation to provide ...</td>\n",
       "      <td>Breaking news: $1 billion donation to provide ...</td>\n",
       "      <td>The New York Times &lt;nytdirect@nytimes.com&gt; Bre...</td>\n",
       "      <td>The New York Times &lt;nytdirect@nytimes.com&gt; Bre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quizlet &lt;newsletter@lifecycle.quizlet.com&gt;</td>\n",
       "      <td>7-week study streak ✅</td>\n",
       "      <td>You're on a roll! 96   Quizlet      /* RESETS ...</td>\n",
       "      <td>Quizlet &lt;newsletter@lifecycle.quizlet.com&gt; 7-w...</td>\n",
       "      <td>Quizlet &lt;newsletter@lifecycle.quizlet.com&gt; 7-w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sender  \\\n",
       "0  Womens Network Dartmouth <Womens.Network.Dartm...   \n",
       "1    Dartmouth Bikes <Dartmouth.Bikes@dartmouth.edu>   \n",
       "2  Collis Governing Board <Collis.Governing.Board...   \n",
       "3         The New York Times <nytdirect@nytimes.com>   \n",
       "4         Quizlet <newsletter@lifecycle.quizlet.com>   \n",
       "\n",
       "                                             Subject  \\\n",
       "0             YOU'RE INVITED: SPA NIGHT TOMORROW 8PM   \n",
       "1  Open Bike Shop Hours (Free Lube!) Tuesday Morn...   \n",
       "2                                      microbrews <3   \n",
       "3  Breaking news: $1 billion donation to provide ...   \n",
       "4                              7-week study streak ✅   \n",
       "\n",
       "                                                Body  \\\n",
       "0  As the term concludes  take a study break and ...   \n",
       "1  Open shop hours are available for the communit...   \n",
       "2  CGB Microbrews where: One Wheelock (Collis) wh...   \n",
       "3  Breaking news: $1 billion donation to provide ...   \n",
       "4  You're on a roll! 96   Quizlet      /* RESETS ...   \n",
       "\n",
       "                                                Meta  \\\n",
       "0  Womens Network Dartmouth <Womens.Network.Dartm...   \n",
       "1  Dartmouth Bikes <Dartmouth.Bikes@dartmouth.edu...   \n",
       "2  Collis Governing Board <Collis.Governing.Board...   \n",
       "3  The New York Times <nytdirect@nytimes.com> Bre...   \n",
       "4  Quizlet <newsletter@lifecycle.quizlet.com> 7-w...   \n",
       "\n",
       "                                                Full  Label  \n",
       "0  Womens Network Dartmouth <Womens.Network.Dartm...      0  \n",
       "1  Dartmouth Bikes <Dartmouth.Bikes@dartmouth.edu...      0  \n",
       "2  Collis Governing Board <Collis.Governing.Board...      0  \n",
       "3  The New York Times <nytdirect@nytimes.com> Bre...      0  \n",
       "4  Quizlet <newsletter@lifecycle.quizlet.com> 7-w...      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check - print first 5 rows of dataset\n",
    "df = pd.read_csv(\"fullDataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536\n"
     ]
    }
   ],
   "source": [
    "# sanity check - check dataset length\n",
    "print(len(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
